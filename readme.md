# A semantic matching model

## 研究问题
文本匹配：实现同义字段的一对一的关联匹配，为字段推荐出相似度最高的topk项

## 实验思路
两个词语之间的词向量求余弦相似度作为相似度比较

高维向量降维计算，采用pca同时实现可视化

多个词语辅助求均值，然后从高到低排序取前k项

## 实验过程
### partⅠ：数据元的处理与加载
本次实验采用腾讯语料库，在 txt2binary.py文件中实现了将语料库中文本形式的词向量转化为npy文件，存入TC.vectors.npy文件，提高了加载与匹配速度
### part Ⅱ：算法精度以及匹配时间
经过几轮实验之后可以把相似度控制在70%以上，匹配时间控制在1s以内，匹配对象以较短的词语为主，topk控制在10-20左右规模。标准数据元在未存在已有词向量中时，通过jieba分词的搜索引擎模式，提高关键词的权重，方便后续的匹配，也减少了OOV问题的出现。
### part Ⅲ：初步结果与改进
该计算方法获得的匹配结果对于短文本匹配度较高，长文本匹配度相对较低。经过溯源发现语料库的数据训练不足。

改进：更换、添加数据来源，训练以及拟合数据

### bonus ：1.pca降维及可视化实现 2.动态加载标准数据元
## 实验结果
### 样例一：

#### 输入：
10 户籍

#### 输出： 


    "户籍": {
        "户口详址": 0.9693046599255895,
        "户籍地乡镇": 0.9602674031553189,
        "户籍地县区": 0.9600680792052114,
        "户籍地省": 0.9594614061457045,
        "户籍地市": 0.9570843975532743,
        "配偶户籍地省市县": 0.9557550088714625,
        "配偶户籍地省市县代码": 0.9483054712822524,
        "户口迁出日期": 0.9428175671291363,
        "户籍地居委会": 0.9409960093041443,
        "户籍地省市县区": 0.9407686691839845
    }



### 样例二：
#### 输入：
6 身份证
#### 输出：


    "身份证": {
        "户主证件号码": 0.9493286135868697,
        "男方身份证件类型": 0.9454443399339698,
        "女方身份证件类型": 0.9447108103489574,
        "配偶证件号码": 0.9414522832851435,
        "子女身份证件类型": 0.9406068030110255,
        "身份证件类型代码": 0.9367530067399868
    }



